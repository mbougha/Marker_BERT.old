{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Marked_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hFm6ylUn8oSu",
        "outputId": "fdaf0132-01e4-4e5f-faf1-e3225d6ce52b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpbpoe4yygpU",
        "colab_type": "text"
      },
      "source": [
        "**Firstly**, we need to set up Colab TPU running environment, verify a TPU device is succesfully connected and upload credentials to TPU for GCS bucket usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRx7coBby4Il",
        "colab_type": "code",
        "outputId": "51a0980d-9cb4-4b04-a1b2-1ba1062cdb2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import sys\n",
        "username=''#@param {type:\"string\"}\n",
        "password=''#@param {type:\"string\"}\n",
        "!test -d MarkedBERT || git clone https://{username}:{password}@github.com/{username}/Marked_BERT.git\n",
        "if not 'Marked_BERT' in sys.path:\n",
        "  sys.path += ['Marked_BERT']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarkedBERT'...\n",
            "remote: Enumerating objects: 186, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/186)\u001b[K\rremote: Counting objects:   1% (2/186)\u001b[K\rremote: Counting objects:   2% (4/186)\u001b[K\rremote: Counting objects:   3% (6/186)\u001b[K\rremote: Counting objects:   4% (8/186)\u001b[K\rremote: Counting objects:   5% (10/186)\u001b[K\rremote: Counting objects:   6% (12/186)\u001b[K\rremote: Counting objects:   7% (14/186)\u001b[K\rremote: Counting objects:   8% (15/186)\u001b[K\rremote: Counting objects:   9% (17/186)\u001b[K\rremote: Counting objects:  10% (19/186)\u001b[K\rremote: Counting objects:  11% (21/186)\u001b[K\rremote: Counting objects:  12% (23/186)\u001b[K\rremote: Counting objects:  13% (25/186)\u001b[K\rremote: Counting objects:  14% (27/186)\u001b[K\rremote: Counting objects:  15% (28/186)\u001b[K\rremote: Counting objects:  16% (30/186)\u001b[K\rremote: Counting objects:  17% (32/186)\u001b[K\rremote: Counting objects:  18% (34/186)\u001b[K\rremote: Counting objects:  19% (36/186)\u001b[K\rremote: Counting objects:  20% (38/186)\u001b[K\rremote: Counting objects:  21% (40/186)\u001b[K\rremote: Counting objects:  22% (41/186)\u001b[K\rremote: Counting objects:  23% (43/186)\u001b[K\rremote: Counting objects:  24% (45/186)\u001b[K\rremote: Counting objects:  25% (47/186)\u001b[K\rremote: Counting objects:  26% (49/186)\u001b[K\rremote: Counting objects:  27% (51/186)\u001b[K\rremote: Counting objects:  28% (53/186)\u001b[K\rremote: Counting objects:  29% (54/186)\u001b[K\rremote: Counting objects:  30% (56/186)\u001b[K\rremote: Counting objects:  31% (58/186)\u001b[K\rremote: Counting objects:  32% (60/186)\u001b[K\rremote: Counting objects:  33% (62/186)\u001b[K\rremote: Counting objects:  34% (64/186)\u001b[K\rremote: Counting objects:  35% (66/186)\u001b[K\rremote: Counting objects:  36% (67/186)\u001b[K\rremote: Counting objects:  37% (69/186)\u001b[K\rremote: Counting objects:  38% (71/186)\u001b[K\rremote: Counting objects:  39% (73/186)\u001b[K\rremote: Counting objects:  40% (75/186)\u001b[K\rremote: Counting objects:  41% (77/186)\u001b[K\rremote: Counting objects:  42% (79/186)\u001b[K\rremote: Counting objects:  43% (80/186)\u001b[K\rremote: Counting objects:  44% (82/186)\u001b[K\rremote: Counting objects:  45% (84/186)\u001b[K\rremote: Counting objects:  46% (86/186)\u001b[K\rremote: Counting objects:  47% (88/186)\u001b[K\rremote: Counting objects:  48% (90/186)\u001b[K\rremote: Counting objects:  49% (92/186)\u001b[K\rremote: Counting objects:  50% (93/186)\u001b[K\rremote: Counting objects:  51% (95/186)\u001b[K\rremote: Counting objects:  52% (97/186)\u001b[K\rremote: Counting objects:  53% (99/186)\u001b[K\rremote: Counting objects:  54% (101/186)\u001b[K\rremote: Counting objects:  55% (103/186)\u001b[K\rremote: Counting objects:  56% (105/186)\u001b[K\rremote: Counting objects:  57% (107/186)\u001b[K\rremote: Counting objects:  58% (108/186)\u001b[K\rremote: Counting objects:  59% (110/186)\u001b[K\rremote: Counting objects:  60% (112/186)\u001b[K\rremote: Counting objects:  61% (114/186)\u001b[K\rremote: Counting objects:  62% (116/186)\u001b[K\rremote: Counting objects:  63% (118/186)\u001b[K\rremote: Counting objects:  64% (120/186)\u001b[K\rremote: Counting objects:  65% (121/186)\u001b[K\rremote: Counting objects:  66% (123/186)\u001b[K\rremote: Counting objects:  67% (125/186)\u001b[K\rremote: Counting objects:  68% (127/186)\u001b[K\rremote: Counting objects:  69% (129/186)\u001b[K\rremote: Counting objects:  70% (131/186)\u001b[K\rremote: Counting objects:  71% (133/186)\u001b[K\rremote: Counting objects:  72% (134/186)\u001b[K\rremote: Counting objects:  73% (136/186)\u001b[K\rremote: Counting objects:  74% (138/186)\u001b[K\rremote: Counting objects:  75% (140/186)\u001b[K\rremote: Counting objects:  76% (142/186)\u001b[K\rremote: Counting objects:  77% (144/186)\u001b[K\rremote: Counting objects:  78% (146/186)\u001b[K\rremote: Counting objects:  79% (147/186)\u001b[K\rremote: Counting objects:  80% (149/186)\u001b[K\rremote: Counting objects:  81% (151/186)\u001b[K\rremote: Counting objects:  82% (153/186)\u001b[K\rremote: Counting objects:  83% (155/186)\u001b[K\rremote: Counting objects:  84% (157/186)\u001b[K\rremote: Counting objects:  85% (159/186)\u001b[K\rremote: Counting objects:  86% (160/186)\u001b[K\rremote: Counting objects:  87% (162/186)\u001b[K\rremote: Counting objects:  88% (164/186)\u001b[K\rremote: Counting objects:  89% (166/186)\u001b[K\rremote: Counting objects:  90% (168/186)\u001b[K\rremote: Counting objects:  91% (170/186)\u001b[K\rremote: Counting objects:  92% (172/186)\u001b[K\rremote: Counting objects:  93% (173/186)\u001b[K\rremote: Counting objects:  94% (175/186)\u001b[K\rremote: Counting objects:  95% (177/186)\u001b[K\rremote: Counting objects:  96% (179/186)\u001b[K\rremote: Counting objects:  97% (181/186)\u001b[K\rremote: Counting objects:  98% (183/186)\u001b[K\rremote: Counting objects:  99% (185/186)\u001b[K\rremote: Counting objects: 100% (186/186)\u001b[K\rremote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/125)\u001b[K\rremote: Compressing objects:   1% (2/125)\u001b[K\rremote: Compressing objects:   2% (3/125)\u001b[K\rremote: Compressing objects:   3% (4/125)\u001b[K\rremote: Compressing objects:   4% (5/125)\u001b[K\rremote: Compressing objects:   5% (7/125)\u001b[K\rremote: Compressing objects:   6% (8/125)\u001b[K\rremote: Compressing objects:   7% (9/125)\u001b[K\rremote: Compressing objects:   8% (10/125)\u001b[K\rremote: Compressing objects:   9% (12/125)\u001b[K\rremote: Compressing objects:  10% (13/125)\u001b[K\rremote: Compressing objects:  11% (14/125)\u001b[K\rremote: Compressing objects:  12% (15/125)\u001b[K\rremote: Compressing objects:  13% (17/125)\u001b[K\rremote: Compressing objects:  14% (18/125)\u001b[K\rremote: Compressing objects:  15% (19/125)\u001b[K\rremote: Compressing objects:  16% (20/125)\u001b[K\rremote: Compressing objects:  17% (22/125)\u001b[K\rremote: Compressing objects:  18% (23/125)\u001b[K\rremote: Compressing objects:  19% (24/125)\u001b[K\rremote: Compressing objects:  20% (25/125)\u001b[K\rremote: Compressing objects:  21% (27/125)\u001b[K\rremote: Compressing objects:  22% (28/125)\u001b[K\rremote: Compressing objects:  23% (29/125)\u001b[K\rremote: Compressing objects:  24% (30/125)\u001b[K\rremote: Compressing objects:  25% (32/125)\u001b[K\rremote: Compressing objects:  26% (33/125)\u001b[K\rremote: Compressing objects:  27% (34/125)\u001b[K\rremote: Compressing objects:  28% (35/125)\u001b[K\rremote: Compressing objects:  29% (37/125)\u001b[K\rremote: Compressing objects:  30% (38/125)\u001b[K\rremote: Compressing objects:  31% (39/125)\u001b[K\rremote: Compressing objects:  32% (40/125)\u001b[K\rremote: Compressing objects:  33% (42/125)\u001b[K\rremote: Compressing objects:  34% (43/125)\u001b[K\rremote: Compressing objects:  35% (44/125)\u001b[K\rremote: Compressing objects:  36% (45/125)\u001b[K\rremote: Compressing objects:  37% (47/125)\u001b[K\rremote: Compressing objects:  38% (48/125)\u001b[K\rremote: Compressing objects:  39% (49/125)\u001b[K\rremote: Compressing objects:  40% (50/125)\u001b[K\rremote: Compressing objects:  41% (52/125)\u001b[K\rremote: Compressing objects:  42% (53/125)\u001b[K\rremote: Compressing objects:  43% (54/125)\u001b[K\rremote: Compressing objects:  44% (55/125)\u001b[K\rremote: Compressing objects:  45% (57/125)\u001b[K\rremote: Compressing objects:  46% (58/125)\u001b[K\rremote: Compressing objects:  47% (59/125)\u001b[K\rremote: Compressing objects:  48% (60/125)\u001b[K\rremote: Compressing objects:  49% (62/125)\u001b[K\rremote: Compressing objects:  50% (63/125)\u001b[K\rremote: Compressing objects:  51% (64/125)\u001b[K\rremote: Compressing objects:  52% (65/125)\u001b[K\rremote: Compressing objects:  53% (67/125)\u001b[K\rremote: Compressing objects:  54% (68/125)\u001b[K\rremote: Compressing objects:  55% (69/125)\u001b[K\rremote: Compressing objects:  56% (70/125)\u001b[K\rremote: Compressing objects:  57% (72/125)\u001b[K\rremote: Compressing objects:  58% (73/125)\u001b[K\rremote: Compressing objects:  59% (74/125)\u001b[K\rremote: Compressing objects:  60% (75/125)\u001b[K\rremote: Compressing objects:  61% (77/125)\u001b[K\rremote: Compressing objects:  62% (78/125)\u001b[K\rremote: Compressing objects:  63% (79/125)\u001b[K\rremote: Compressing objects:  64% (80/125)\u001b[K\rremote: Compressing objects:  65% (82/125)\u001b[K\rremote: Compressing objects:  66% (83/125)\u001b[K\rremote: Compressing objects:  67% (84/125)\u001b[K\rremote: Compressing objects:  68% (85/125)\u001b[K\rremote: Compressing objects:  69% (87/125)\u001b[K\rremote: Compressing objects:  70% (88/125)\u001b[K\rremote: Compressing objects:  71% (89/125)\u001b[K\rremote: Compressing objects:  72% (90/125)\u001b[K\rremote: Compressing objects:  73% (92/125)\u001b[K\rremote: Compressing objects:  74% (93/125)\u001b[K\rremote: Compressing objects:  75% (94/125)\u001b[K\rremote: Compressing objects:  76% (95/125)\u001b[K\rremote: Compressing objects:  77% (97/125)\u001b[K\rremote: Compressing objects:  78% (98/125)\u001b[K\rremote: Compressing objects:  79% (99/125)\u001b[K\rremote: Compressing objects:  80% (100/125)\u001b[K\rremote: Compressing objects:  81% (102/125)\u001b[K\rremote: Compressing objects:  82% (103/125)\u001b[K\rremote: Compressing objects:  83% (104/125)\u001b[K\rremote: Compressing objects:  84% (105/125)\u001b[K\rremote: Compressing objects:  85% (107/125)\u001b[K\rremote: Compressing objects:  86% (108/125)\u001b[K\rremote: Compressing objects:  87% (109/125)\u001b[K\rremote: Compressing objects:  88% (110/125)\u001b[K\rremote: Compressing objects:  89% (112/125)\u001b[K\rremote: Compressing objects:  90% (113/125)\u001b[K\rremote: Compressing objects:  91% (114/125)\u001b[K\rremote: Compressing objects:  92% (115/125)\u001b[K\rremote: Compressing objects:  93% (117/125)\u001b[K\rremote: Compressing objects:  94% (118/125)\u001b[K\rremote: Compressing objects:  95% (119/125)\u001b[K\rremote: Compressing objects:  96% (120/125)\u001b[K\rremote: Compressing objects:  97% (122/125)\u001b[K\rremote: Compressing objects:  98% (123/125)\u001b[K\rremote: Compressing objects:  99% (124/125)\u001b[K\rremote: Compressing objects: 100% (125/125)\u001b[K\rremote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "Receiving objects:   0% (1/438)   \rReceiving objects:   1% (5/438)   \rReceiving objects:   2% (9/438)   \rReceiving objects:   3% (14/438)   \rReceiving objects:   4% (18/438)   \rReceiving objects:   5% (22/438)   \rReceiving objects:   6% (27/438)   \rReceiving objects:   7% (31/438)   \rReceiving objects:   8% (36/438)   \rReceiving objects:   9% (40/438)   \rReceiving objects:  10% (44/438)   \rReceiving objects:  11% (49/438)   \rReceiving objects:  12% (53/438)   \rReceiving objects:  13% (57/438)   \rReceiving objects:  14% (62/438)   \rReceiving objects:  15% (66/438)   \rReceiving objects:  16% (71/438)   \rReceiving objects:  17% (75/438)   \rReceiving objects:  18% (79/438)   \rReceiving objects:  19% (84/438)   \rReceiving objects:  20% (88/438)   \rReceiving objects:  21% (92/438)   \rReceiving objects:  22% (97/438)   \rReceiving objects:  23% (101/438)   \rReceiving objects:  24% (106/438)   \rReceiving objects:  25% (110/438)   \rReceiving objects:  26% (114/438)   \rReceiving objects:  27% (119/438)   \rReceiving objects:  28% (123/438)   \rReceiving objects:  29% (128/438)   \rReceiving objects:  30% (132/438)   \rReceiving objects:  31% (136/438)   \rReceiving objects:  32% (141/438)   \rReceiving objects:  33% (145/438)   \rReceiving objects:  34% (149/438)   \rReceiving objects:  35% (154/438)   \rReceiving objects:  36% (158/438)   \rReceiving objects:  37% (163/438)   \rReceiving objects:  38% (167/438)   \rReceiving objects:  39% (171/438)   \rReceiving objects:  40% (176/438)   \rReceiving objects:  41% (180/438)   \rReceiving objects:  42% (184/438)   \rReceiving objects:  43% (189/438)   \rReceiving objects:  44% (193/438)   \rReceiving objects:  45% (198/438)   \rReceiving objects:  46% (202/438)   \rReceiving objects:  47% (206/438)   \rReceiving objects:  48% (211/438)   \rReceiving objects:  49% (215/438)   \rReceiving objects:  50% (219/438)   \rReceiving objects:  51% (224/438)   \rReceiving objects:  52% (228/438)   \rReceiving objects:  53% (233/438)   \rReceiving objects:  54% (237/438)   \rReceiving objects:  55% (241/438)   \rReceiving objects:  56% (246/438)   \rReceiving objects:  57% (250/438)   \rReceiving objects:  58% (255/438)   \rReceiving objects:  59% (259/438)   \rReceiving objects:  60% (263/438)   \rReceiving objects:  61% (268/438)   \rReceiving objects:  62% (272/438)   \rReceiving objects:  63% (276/438)   \rReceiving objects:  64% (281/438)   \rReceiving objects:  65% (285/438)   \rReceiving objects:  66% (290/438)   \rReceiving objects:  67% (294/438)   \rReceiving objects:  68% (298/438)   \rReceiving objects:  69% (303/438)   \rReceiving objects:  70% (307/438)   \rReceiving objects:  71% (311/438)   \rReceiving objects:  72% (316/438)   \rReceiving objects:  73% (320/438)   \rReceiving objects:  74% (325/438)   \rReceiving objects:  75% (329/438)   \rReceiving objects:  76% (333/438)   \rReceiving objects:  77% (338/438)   \rReceiving objects:  78% (342/438)   \rremote: Total 438 (delta 125), reused 117 (delta 58), pack-reused 252\u001b[K\n",
            "Receiving objects:  79% (347/438)   \rReceiving objects:  80% (351/438)   \rReceiving objects:  81% (355/438)   \rReceiving objects:  82% (360/438)   \rReceiving objects:  83% (364/438)   \rReceiving objects:  84% (368/438)   \rReceiving objects:  85% (373/438)   \rReceiving objects:  86% (377/438)   \rReceiving objects:  87% (382/438)   \rReceiving objects:  88% (386/438)   \rReceiving objects:  89% (390/438)   \rReceiving objects:  90% (395/438)   \rReceiving objects:  91% (399/438)   \rReceiving objects:  92% (403/438)   \rReceiving objects:  93% (408/438)   \rReceiving objects:  94% (412/438)   \rReceiving objects:  95% (417/438)   \rReceiving objects:  96% (421/438)   \rReceiving objects:  97% (425/438)   \rReceiving objects:  98% (430/438)   \rReceiving objects:  99% (434/438)   \rReceiving objects: 100% (438/438)   \rReceiving objects: 100% (438/438), 87.84 KiB | 1.91 MiB/s, done.\n",
            "Resolving deltas:   0% (0/280)   \rResolving deltas:   3% (10/280)   \rResolving deltas:   5% (14/280)   \rResolving deltas:   7% (21/280)   \rResolving deltas:   8% (23/280)   \rResolving deltas:  17% (48/280)   \rResolving deltas:  18% (52/280)   \rResolving deltas:  25% (71/280)   \rResolving deltas:  26% (74/280)   \rResolving deltas:  31% (88/280)   \rResolving deltas:  52% (146/280)   \rResolving deltas:  67% (188/280)   \rResolving deltas:  72% (203/280)   \rResolving deltas:  73% (205/280)   \rResolving deltas:  75% (212/280)   \rResolving deltas:  76% (215/280)   \rResolving deltas:  77% (216/280)   \rResolving deltas:  79% (223/280)   \rResolving deltas:  80% (226/280)   \rResolving deltas:  87% (246/280)   \rResolving deltas:  92% (259/280)   \rResolving deltas:  93% (261/280)   \rResolving deltas:  97% (273/280)   \rResolving deltas:  98% (277/280)   \rResolving deltas: 100% (280/280)   \rResolving deltas: 100% (280/280), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C0eAqa5g13Y6",
        "colab": {}
      },
      "source": [
        "!pip install -r MarkedBERT/requirements_colab.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e0367d23-2f30-4833-baa3-5b1d17db9edf",
        "id": "RCbDvDYx13ZB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-dev20200311'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdUFaYR4wwZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pt-66aNExJMK"
      },
      "source": [
        "# DATA FILES NEED TO BE IN GCS BUCKET SO THAT THE TPU CAN ACCESS IT \n",
        "THE FIRST RUN: THE TPU HAS NO ACCESS PERMISSIONS TO THE BUCKET SO U NEED TO CHANGE THE PERMISSIONS OF YOUR BUCKET MANUALLY TO ADD THE TPU ( THE NAME WILL BE IN THE EXCEPTION TEXT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJvKZN02w2j4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['COLAB_SKIP_TPU_AUTH'] = '1'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FaSBpUMw6dZ",
        "colab_type": "code",
        "outputId": "daed64a3-4a38-4fc2-de9f-0bde91b0587b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "project_id=\"GCS project id \"#@param {type:\"string\"}\n",
        "bucket_name=\"Bucket where data is stored\"#@param {type:\"string\"}\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJEo5ZakzPNo",
        "colab_type": "text"
      },
      "source": [
        "**Thirdly**, prepare for training:\n",
        "\n",
        "* Specify training data.\n",
        "* Specify BERT pretrained model\n",
        "* Specify GS bucket, create output directory for model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NsGKuHdzWzZ",
        "colab_type": "code",
        "outputId": "0348a342-0d3d-4bd6-c67e-ea6218f0f939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MODEL_TYPE = \"bert\" #@param {type:\"string\"}\n",
        "MODEL_NAME = \"bert-base-uncased\" #@param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = \"gs://my_bucket/output_dir/\" #@param {type:\"string\"}\n",
        "assert OUTPUT_DIR, 'Must specify an existing GCS bucket name'\n",
        "tf.io.gfile.makedirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Now we need to specify the input data dir. Should contain the .tfrecord files \n",
        "# and the supporting query-docids mapping files.\n",
        "DATA_DIR = \"gs://my_bucket/train_data\" #@param {type:\"string\"}\n",
        "print('***** Data directory: {} *****'.format(DATA_DIR))\n",
        "\n",
        "FILE_NAME= \"dataset_trec_mu_pair.tf\" #@param {type:\"string\"}\n",
        "SET_NAME= \"trec\" #@param {type:\"string\"}\n",
        "\n",
        "# need to mount your drive and put the path to the directory containing the .h5 file\n",
        "CHKPT_PATH=\"/content/drive/My Drive/checkpoints/base\" #@param {type:\"string\"}\n",
        "\n",
        "STRATEGY= \"mu_mark_pass\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://lila_data/output_dir/un_mark_pass *****\n",
            "***** Data directory: gs://lila_data/train *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_d4sfn0g-R",
        "colab_type": "text"
      },
      "source": [
        "**Now, we can start training/evaluating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jBv9QA3X13Zj",
        "colab": {}
      },
      "source": [
        "# coding=utf-8\n",
        "import collections\n",
        "import datetime\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from absl import app, flags, logging\n",
        "from tqdm import  trange\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import (\n",
        "    TF2_WEIGHTS_NAME,\n",
        "    BertConfig,\n",
        "    BertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaTokenizer,\n",
        "    TFBertForSequenceClassification,\n",
        "    TFDistilBertForSequenceClassification,\n",
        "    TFRobertaForSequenceClassification,\n",
        ")\n",
        "#local modules\n",
        "from Processors import Robust04Processor, MsMarcoDocumentProcessor, MsMarcoPassageProcessor, DocumentHandle, DocumentSplitterHandle, PassageHandle, get_marker"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "37v3LH-I13Zn",
        "colab": {}
      },
      "source": [
        "ALL_MODELS = sum(\n",
        "    (tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig, RobertaConfig, DistilBertConfig)), ()\n",
        ")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, TFBertForSequenceClassification, BertTokenizer),\n",
        "    \"roberta\": (RobertaConfig, TFRobertaForSequenceClassification, RobertaTokenizer),\n",
        "    \"distilbert\": (DistilBertConfig, TFDistilBertForSequenceClassification, DistilBertTokenizer),\n",
        "}\n",
        "\n",
        "#Arguments \n",
        "args=dict()\n",
        "\n",
        "args[\"data_dir\"]= DATA_DIR\n",
        "args[\"model_type\"]=MODEL_TYPE\n",
        "args[\"model_name_or_path\"]=MODEL_NAME\n",
        "args[\"output_dir\"]=OUTPUT_DIR\n",
        "args[\"transformer_checkpoints\"]= CHKPT_PATH\n",
        "args[\"max_seq_length\"]=512\n",
        "args[\"tpu\"]= f\"grpc://{os.environ['COLAB_TPU_ADDR']}\"\n",
        "args[\"do_train\"]= False\n",
        "args['do_eval']= True\n",
        "args[\"per_device_train_batch_size\"]= 16\n",
        "args['per_device_eval_batch_size']= 4\n",
        "args[\"max_steps\"]=100000\n",
        "args[\"warmup_steps\"]=10000\n",
        "args[\"learning_rate\"]=3e-6\n",
        "args[\"adam_epsilon\"]=1e-8\n",
        "args[\"logging_steps\"]=100\n",
        "args[\"seed\"]=42\n",
        "args[\"max_grad_norm\"]=1.0\n",
        "args[\"save_steps\"]=5000\n",
        "args[\"overwrite_output_dir\"]=False\n",
        "args[\"fp16\"]=False\n",
        "args[\"no_cuda\"]=False\n",
        "args['gpus']=None\n",
        "args['config_name']=None\n",
        "args['cache_dir']=None\n",
        "args['tokenizer_name']=None\n",
        "args['num_tpu_cores']=8\n",
        "args['do_predict']=False\n",
        "args['evaluate_during_training']=False\n",
        "args['do_lower_case']=False\n",
        "args['num_train_epochs']=1\n",
        "args['overwrite_cache']=False\n",
        "args['eval_all_checkpoints']=False\n",
        "args[\"msmarco_output\"]= True\n",
        "args[\"num_eval_docs\"] =1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1BVqcDD13Zz",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(\n",
        "    args, strategy,  train_dataset, model, num_train_examples, train_batch_size\n",
        "):\n",
        "    if args[\"max_steps\"] > 0:\n",
        "        num_train_steps = args[\"max_steps\"] \n",
        "        args[\"num_train_epochs\"] = 1 # only consider the case where max_steps < one_epoch_steps\n",
        "    else:\n",
        "        num_train_steps = (\n",
        "            math.ceil(num_train_examples / train_batch_size)\n",
        "            * args[\"num_train_epochs\"]\n",
        "        )\n",
        "\n",
        "    with strategy.scope():\n",
        "        loss_fct = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "        optimizer = create_optimizer(args[\"learning_rate\"], num_train_steps, args[\"warmup_steps\"])\n",
        "\n",
        "        if args[\"fp16\"]:\n",
        "            optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, \"dynamic\")\n",
        "\n",
        "        loss_metric = tf.keras.metrics.Mean(name=\"loss\", dtype=tf.float32)\n",
        "        \n",
        "    logging.info(\"***** Running training *****\")\n",
        "    logging.info(\"  Num examples = %d\", num_train_examples)\n",
        "    logging.info(\"  Num Epochs = %d\", args[\"num_train_epochs\"])\n",
        "    logging.info(\"  Instantaneous batch size per device = %d\", args[\"per_device_train_batch_size\"])\n",
        "    logging.info(\n",
        "        \"  Total train batch size (w. parallel, distributed ) = %d\",\n",
        "        train_batch_size,\n",
        "    )\n",
        "\n",
        "    logging.info(\"  Total training steps = %d\", num_train_steps)\n",
        "\n",
        "    model.summary()    \n",
        "\n",
        "    @tf.function\n",
        "    def train_step(train_features, train_labels):\n",
        "        def step_fn(train_features, train_labels):\n",
        "            inputs = {\"attention_mask\": train_features[\"attention_mask\"], \"training\": True}\n",
        "\n",
        "            if args[\"model_type\"] != \"distilbert\":\n",
        "                inputs[\"token_type_ids\"] = (\n",
        "                    train_features[\"token_type_ids\"] if args[\"model_type\"] in [\"bert\", \"xlnet\"] else None\n",
        "                )\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(train_features[\"input_ids\"], **inputs)[0]\n",
        "                cross_entropy = loss_fct(train_labels, logits) #per_example_losses\n",
        "                loss = tf.reduce_sum(cross_entropy) * (1.0 / train_batch_size) #per_replica_loss\n",
        "                if args['fp16']:\n",
        "                    scaled_loss = optimizer.get_scaled_loss(loss)\n",
        "\n",
        "            if args['fp16']:\n",
        "              scaled_grads = tape.gradient(scaled_loss, model.trainable_variables)\n",
        "              grads = optimizer.get_unscaled_gradients(scaled_grads)\n",
        "            else:\n",
        "              grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            return cross_entropy\n",
        "\n",
        "        per_example_losses = strategy.experimental_run_v2(step_fn, args=(train_features, train_labels))\n",
        "        sum_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_example_losses, axis=0)\n",
        "        \n",
        "        return sum_loss / train_batch_size #loss over replicas\n",
        "\n",
        "    current_time = datetime.datetime.now()\n",
        "\n",
        "    # Train or resume training from chkpt\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    current_step = 0\n",
        "\n",
        "    with strategy.scope():\n",
        "        # Check if continuing training from a checkpoint\n",
        "        checkpoint = tf.train.Checkpoint(step=tf.Variable(0), model=model, optimizer=optimizer)\n",
        "        manager = tf.train.CheckpointManager(checkpoint, f'{args[\"output_dir\"]}/tf_ckpts', max_to_keep=3)\n",
        "        latest_checkpoint_file = manager.latest_checkpoint\n",
        "        if latest_checkpoint_file:\n",
        "          logging.info(\n",
        "              'Checkpoint file %s found and restoring from '\n",
        "              'checkpoint', latest_checkpoint_file)\n",
        "          checkpoint.restore(latest_checkpoint_file)\n",
        "          logging.info('Loading from checkpoint file completed')\n",
        "    if latest_checkpoint_file:\n",
        "        current_step = optimizer.iterations.numpy()\n",
        "        logging.info(\n",
        "              'Resume training from step %s', current_step )\n",
        "    print(\"\\ncurrent step = \", current_step)\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    epoch_iterator = trange(\n",
        "        epochs_trained, int(args[\"num_train_epochs\"]), desc=\"Epoch\")\n",
        "    global_step = current_step \n",
        "    # global_step without gradient_accumul ==step (useless) \n",
        "    #if multiple epochs global_step may contain steps from multiple epochs, \n",
        "    #step should be step_in_current_epoch, epochs_trained calculated\n",
        "\n",
        "    for epoch in epoch_iterator:\n",
        "        train_iterator = tqdm(train_dataset, total=num_train_steps, desc=\"Iteration\")\n",
        "\n",
        "        with strategy.scope():\n",
        "            for step, (train_features, train_labels) in enumerate(train_iterator):\n",
        "                # Skip past any already trained steps if resuming training\n",
        "                if current_step > 0:\n",
        "                    current_step -= 1\n",
        "                    continue\n",
        "\n",
        "                loss = train_step(train_features, train_labels)\n",
        "                    \n",
        "                loss_metric(loss)\n",
        "\n",
        "                global_step += 1\n",
        "                checkpoint.step.assign_add(1)\n",
        "\n",
        "                if args[\"logging_steps\"] > 0 and global_step % args[\"logging_steps\"] == 0:\n",
        "                        # Log metrics\n",
        "                        lr = optimizer.learning_rate\n",
        "                        learning_rate = lr(step)\n",
        "                        \n",
        "                        logging_loss = loss_metric.result()\n",
        "\n",
        "                        train_iterator.set_postfix(loss=logging_loss.numpy(), step=global_step, lr=learning_rate.numpy())\n",
        "\n",
        "                if args[\"save_steps\"] > 0 and global_step % args[\"save_steps\"] == 0:\n",
        "                        ## TF2 checkpoint for training \n",
        "                        save_path = manager.save()\n",
        "                        logging.info(\"Saved checkpoint for step %s: %s\",global_step,save_path)\n",
        "                        \n",
        "                if args[\"save_steps\"] > 0 and global_step % (args[\"save_steps\"]*10) == 0:\n",
        "                        # Save model checkpoint\n",
        "                        output_dir = os.path.join(args[\"transformer_checkpoints\"], f\"checkpoint-{global_step}\")\n",
        "\n",
        "                        if not os.path.exists(output_dir):\n",
        "                            os.makedirs(output_dir)\n",
        "\n",
        "                        model.save_pretrained(output_dir)\n",
        "                        \n",
        "                        logging.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "                if args['max_steps'] > 0 and global_step > args['max_steps']:\n",
        "                    train_iterator.close()\n",
        "                    break\n",
        "        if args['max_steps'] > 0 and global_step > args['max_steps']:\n",
        "            epoch_iterator.close()\n",
        "            break\n",
        "\n",
        "        epoch_iterator.write(f\"loss epoch {epoch + 1}: {loss_metric.result()}\")\n",
        "\n",
        "        loss_metric.reset_states()\n",
        "\n",
        "    logging.info(\"  Training took time = {}\".format(datetime.datetime.now() - current_time))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TmBXcLBJrgWT",
        "colab": {}
      },
      "source": [
        "def evaluate(args, strategy, eval_dataset, trained_model, num_eval_examples,\n",
        "            eval_batch_size, global_step):\n",
        "\n",
        "    @tf.function\n",
        "    def eval_step(features, labels):\n",
        "      \"\"\"Computes predictions on distributed devices.\"\"\"\n",
        "\n",
        "      def _eval_step_fn(eval_features, labels):\n",
        "        \"\"\"Replicated predictions.\"\"\"\n",
        "        inputs = {\"attention_mask\": eval_features[\"attention_mask\"], \"training\": False}\n",
        "\n",
        "        if args[\"model_type\"] != \"distilbert\":\n",
        "            inputs[\"token_type_ids\"] = (\n",
        "                eval_features[\"token_type_ids\"] if args[\"model_type\"] in [\"bert\", \"xlnet\"] else None\n",
        "            )\n",
        "\n",
        "        logits = trained_model(eval_features[\"input_ids\"], **inputs)[0]\n",
        "\n",
        "        return logits, labels, eval_features['q_id'], eval_features['d_id']\n",
        "\n",
        "      preds, labels, q_id, d_id = strategy.experimental_run_v2(\n",
        "          _eval_step_fn, args=(features, labels))\n",
        "      # outputs: current batch logits as a tuple of shard logits\n",
        "      preds = tf.nest.map_structure(strategy.experimental_local_results,\n",
        "                                      preds)\n",
        "      labels = tf.nest.map_structure(strategy.experimental_local_results, labels)\n",
        "      q_id = tf.nest.map_structure(strategy.experimental_local_results,\n",
        "                                      q_id)\n",
        "      d_id = tf.nest.map_structure(strategy.experimental_local_results,\n",
        "                                      d_id)\n",
        "      return preds, labels, q_id, d_id\n",
        "\n",
        "    \n",
        "    #start eval\n",
        "    num_eval_steps = (\n",
        "            math.ceil(num_eval_examples / eval_batch_size)\n",
        "        )\n",
        "    logging.info(\"***** Running evaluation *****\")\n",
        "    logging.info(\"  Num examples = %d\", num_eval_examples)\n",
        "    logging.info(\"  Instantaneous batch size per device = %d\", \n",
        "                 args[\"per_device_eval_batch_size\"])\n",
        "    logging.info(\n",
        "        \"  Total train batch size (w. parallel, distributed ) = %d\",\n",
        "        eval_batch_size,\n",
        "    )\n",
        "\n",
        "    logging.info(\"  Total evaluation steps = %d\", num_eval_steps)\n",
        "    eval_iterator = tqdm(eval_dataset, total=num_eval_steps, \n",
        "                                   desc=\"Iteration\")\n",
        "\n",
        "    preds = None\n",
        "    golds = None\n",
        "    qids = None\n",
        "    dids= None\n",
        "    msmarco_file = tf.io.gfile.GFile( f\"{args['output_dir']}/predictions_{SET_NAME}_{global_step}.tsv\", 'w')\n",
        "    for step, (eval_features, eval_labels) in enumerate(eval_iterator):\n",
        "        with strategy.scope():\n",
        "            outputs, labels, q_ids, d_ids  = eval_step(eval_features, eval_labels)\n",
        "        \n",
        "        for i in range(args['n_device']):\n",
        "            if preds is None:\n",
        "                preds = outputs[i].numpy()[:,1]\n",
        "                golds = labels[i].numpy()\n",
        "                qids = q_ids[i].numpy()\n",
        "                dids = d_ids[i].numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, outputs[i].numpy()[:,1], axis=0)\n",
        "                golds = np.append(golds, labels[i].numpy(), axis=0)\n",
        "                qids = np.append(qids, q_ids[i].numpy(), axis=0)\n",
        "                dids = np.append(dids, d_ids[i].numpy(), axis=0)\n",
        "                \n",
        "        for qid,did,pred,label in zip(qids,dids,preds,golds):\n",
        "              msmarco_file.write(\"\\t\".join((str(qid), str(did), str(pred), str(label))) + \"\\n\")\n",
        "        preds = None\n",
        "        golds = None\n",
        "        qids = None\n",
        "        dids= None\n",
        "    msmarco_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dgn4zafy13Zr",
        "colab": {}
      },
      "source": [
        "def main(args):\n",
        "    logging.set_verbosity(logging.INFO)\n",
        "\n",
        "    if args[\"fp16\"]:\n",
        "        tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
        "\n",
        "    if args[\"tpu\"]:\n",
        "        print(args['tpu'])\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=args[\"tpu\"])\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)       \n",
        "        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "        args[\"n_device\"] = args[\"num_tpu_cores\"]\n",
        "\n",
        "    elif args[\"no_cuda\"]:\n",
        "        args[\"n_device\"] = 1\n",
        "        strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
        "\n",
        "    elif args[\"gpus\"]:\n",
        "        if len(args[\"gpus\"].split(\",\")) > 1:\n",
        "            args[\"n_device\"] = len([f\"/gpu:{gpu}\" for gpu in args[\"gpus\"].split(\",\")])\n",
        "            strategy = tf.distribute.MirroredStrategy(devices=[f\"/gpu:{gpu}\" for gpu in args[\"gpus\"].split(\",\")])\n",
        "        else:\n",
        "            args[\"n_device\"] = len(args[\"gpus\"].split(\",\"))\n",
        "            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:\" + args[\"gpus\"].split(\",\")[0])\n",
        "\n",
        "    else:\n",
        "        devices = get_available_gpus()\n",
        "        logging.info(\"\\ndevices= %s \\n\", devices)\n",
        "        args[\"n_device\"] = len(devices)\n",
        "        strategy = tf.distribute.MirroredStrategy(devices=devices)\n",
        "    \n",
        "    logging.warning(\n",
        "        \"n_device: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args[\"n_device\"],\n",
        "        bool(args[\"n_device\"] > 1),\n",
        "        args[\"fp16\"],\n",
        "    )\n",
        "    \n",
        "    logging.info(\"\\nStrategy = %s\\n\",strategy)\n",
        "\n",
        "    num_labels = 2\n",
        "    tf.random.set_seed(args[\"seed\"])\n",
        "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args[\"model_type\"]]\n",
        "    config = config_class.from_pretrained(\n",
        "        args[\"config_name\"] if args[\"config_name\"] else args[\"model_name_or_path\"],\n",
        "        num_labels=num_labels,\n",
        "        cache_dir=args[\"cache_dir\"] if args[\"cache_dir\"] else None,\n",
        "    )\n",
        "\n",
        "    logging.info(\"Training/evaluation parameters %s\", args)\n",
        "    \n",
        "    # Training\n",
        "    if args[\"do_train\"]:\n",
        "        # tokenizer = tokenizer_class.from_pretrained(\n",
        "        #     args[\"tokenizer_name\"] if args[\"tokenizer_name\"] else args[\"model_name_or_path\"],\n",
        "        #     do_lower_case=args[\"do_lower_case\"],\n",
        "        #     cache_dir=args[\"cache_dir\"] if args[\"cache_dir\"] else None,\n",
        "        # )\n",
        "\n",
        "        with strategy.scope():\n",
        "            model = model_class.from_pretrained(\n",
        "                args[\"model_name_or_path\"],\n",
        "                from_pt=bool(\".bin\" in args[\"model_name_or_path\"]),\n",
        "                config=config,\n",
        "                cache_dir=args[\"cache_dir\"] if args[\"cache_dir\"] else None,\n",
        "            )\n",
        "            model.layers[-1].activation = tf.keras.activations.softmax\n",
        "\n",
        "        train_batch_size = args[\"per_device_train_batch_size\"] * max(1,args[\"n_device\"])\n",
        "\n",
        "        filename = tf.io.gfile.glob(f\"{args['data_dir']}/{FILE_NAME}\")\n",
        "        train_dataset, num_train_examples = get_dataset( filename,\n",
        "                train_batch_size, args[\"max_seq_length\"], is_training_set=True\n",
        "        )\n",
        "        train_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "        train(\n",
        "            args,\n",
        "            strategy,\n",
        "            train_dataset,\n",
        "            model,\n",
        "            num_train_examples,\n",
        "            train_batch_size,\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(args[\"transformer_checkpoints\"]):\n",
        "            os.makedirs(args[\"transformer_checkpoints\"])\n",
        "\n",
        "        logging.info(\"Saving model to %s\", args[\"transformer_checkpoints\"])\n",
        "\n",
        "        model.save_pretrained(args[\"transformer_checkpoints\"])\n",
        "        #tokenizer.save_pretrained(args[\"transformer_checkpoints\"])\n",
        "    # Evaluating\n",
        "    if args[\"do_eval\"]:\n",
        "        checkpoints = []\n",
        "\n",
        "        if args[\"eval_all_checkpoints\"]:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c)\n",
        "                for c in sorted(\n",
        "                    glob.glob(args[\"transformer_checkpoints\"] + \"/**/\" + TF2_WEIGHTS_NAME, recursive=True),\n",
        "                    key=lambda f: int(\"\".join(filter(str.isdigit, f)) or -1),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if len(checkpoints) == 0:\n",
        "            ##last checkpoint\n",
        "            checkpoints = list(\n",
        "                  os.path.dirname(c)\n",
        "                  for c in sorted(\n",
        "                      glob.glob(args[\"transformer_checkpoints\"] + \"/**/\" + TF2_WEIGHTS_NAME, recursive=True),\n",
        "                      key=lambda f: int(\"\".join(filter(str.isdigit, f)) or -1),\n",
        "                  )\n",
        "              )\n",
        "            checkpoints = [checkpoints[-1]]\n",
        "            \n",
        "            # checkpoints.append(args[\"transformer_checkpoints\"])\n",
        "        \n",
        "        logging.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        \n",
        "\n",
        "        # modified section\n",
        "        tokenizer = tokenizer_class.from_pretrained(\n",
        "            args[\"tokenizer_name\"] if args[\"tokenizer_name\"] else args[\"model_name_or_path\"],\n",
        "            do_lower_case=args[\"do_lower_case\"],\n",
        "            cache_dir=args[\"cache_dir\"] if args[\"cache_dir\"] else None,\n",
        "        )\n",
        "\n",
        "        marker = get_marker(STRATEGY.lower())\n",
        "\n",
        "        handle = DocumentSplitterHandle(tokenizer, args['max_seq_length'])\n",
        "        doc_processor = Robust04Processor(handle,marker)\n",
        "\n",
        "        eval_batch_size = args[\"per_device_eval_batch_size\"] * max(1,args[\"n_device\"])\n",
        "\n",
        "        filename = tf.io.gfile.glob(f\"{args['data_dir']}/{FILE_NAME}\")\n",
        "        eval_dataset, num_eval_examples = doc_processor.get_eval_dataset(filename, eval_batch_size)\n",
        "        print('num_eval_examples= ', num_eval_examples)\n",
        "        eval_dataset = strategy.experimental_distribute_dataset(eval_dataset)\n",
        "\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if re.match(\".*checkpoint-[0-9]\", checkpoint) else \"final\"\n",
        "            print(\"global step= \", global_step)\n",
        "\n",
        "            with strategy.scope():\n",
        "                trained_model = model_class.from_pretrained(checkpoint)\n",
        "                trained_model.summary()\n",
        "        \n",
        "            evaluate(\n",
        "                args,\n",
        "                strategy,\n",
        "                eval_dataset,\n",
        "                trained_model,\n",
        "                num_eval_examples,\n",
        "                eval_batch_size,\n",
        "                global_step,\n",
        "            )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvAZ2AHC1KQi",
        "colab_type": "code",
        "outputId": "7b8178a2-b8a4-4c78-e5e4-4f330728e78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "65c3b053ff2745929bf5002a6e98477f",
            "9eb6fcf8a4de4c2cb66ebb121da37302",
            "0f66f9a1919747b5817c4a1f013257d0",
            "5fa82ee2d9944a4bad1bccf35f0d0c26",
            "f669512a74b84bb7b55e9999e5ce2a03",
            "385a422b3dcd4043b9b552b2e934d9e1",
            "f69b3685b8d644b6bffefec38e5add56",
            "a251963240fe4314956c529914565aec",
            "a187a4d5b0dd44d2a18dbd8c9a0dc08e",
            "f72727e1170e4d78a0dee057a6d0ea80",
            "e794bb248fdd488e9cab2bc909860e12",
            "3358720e4e74407ba4547f9898fb642c",
            "949e4299cab7432ba7bc9b1c1f8abbb2",
            "3af6bbf8c5b14bd498c560e79f151be1",
            "187741b04bea4531897ccd676ca6f3b6",
            "45fd59da529e4f55b843693d4465243d",
            "3e6cad0cb5e64f9f9166419a1f7d233e",
            "6d01143380df4b5ea2118f4f514250b4",
            "3a73b4fd6ea54dfa8c2450cd940aa6ca",
            "0750ee21ac1048308cca472add340a04",
            "d1b6b4e874174645ba54311c8fc20edb",
            "34e5464c18e0433a9a5671a4913bf52e",
            "04471e4945b9417c830d4b6f3bfb3ddc",
            "ee580102f4dc48debc0f37be6a2c43eb",
            "84d1fd34db0f4914aef3037ddce204de",
            "bb6810ccc8ef4d2cb5b4971429176b2a",
            "8e2f3dea37224965905c49f5174d2c6e",
            "bf89c749bf544ffe943b0ad011aa6684",
            "eca086410cd14750a002b2add5074a5d",
            "b82f11a0f4f74087a19f139c56706a81",
            "9e966727922447d4aadf99f922b65d21",
            "a6f820d5594f41488b89f0af95741876"
          ]
        }
      },
      "source": [
        "main(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "grpc://10.16.246.122:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.246.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.246.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "WARNING:absl:n_device: 8, distributed training: True, 16-bits training: False\n",
            "INFO:absl:\n",
            "Strategy = <tensorflow.python.distribute.tpu_strategy.TPUStrategy object at 0x7f457bfbf6a0>\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65c3b053ff2745929bf5002a6e98477f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width="
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Training/evaluation parameters {'data_dir': 'gs://lila_data/train', 'model_type': 'bert', 'model_name_or_path': 'bert-base-uncased', 'output_dir': 'gs://lila_data/output_dir/un_mark_pass', 'transformer_checkpoints': '/content/drive/My Drive/checkpoints/un_mark_pass', 'max_seq_length': 512, 'tpu': 'grpc://10.16.246.122:8470', 'do_train': True, 'do_eval': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 4, 'max_steps': 100000, 'warmup_steps': 10000, 'learning_rate': 3e-06, 'adam_epsilon': 1e-08, 'logging_steps': 100, 'seed': 42, 'max_grad_norm': 1.0, 'save_steps': 5000, 'overwrite_output_dir': False, 'fp16': False, 'no_cuda': False, 'gpus': None, 'config_name': None, 'cache_dir': None, 'tokenizer_name': None, 'num_tpu_cores': 8, 'do_predict': False, 'evaluate_during_training': False, 'do_lower_case': False, 'num_train_epochs': 1, 'overwrite_cache': False, 'eval_all_checkpoints': False, 'msmarco_output': True, 'num_eval_docs': 1000, 'n_device': 8}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a187a4d5b0dd44d2a18dbd8c9a0dc08e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6cad0cb5e64f9f9166419a1f7d233e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=536063208, style=ProgressStyle(description_"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:***** Running training *****\n",
            "INFO:absl:  Num examples = 79561622\n",
            "INFO:absl:  Num Epochs = 1\n",
            "INFO:absl:  Instantaneous batch size per device = 16\n",
            "INFO:absl:  Total train batch size (w. parallel, distributed ) = 128\n",
            "INFO:absl:  Total training steps = 100000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Checkpoint file gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-13 found and restoring from checkpoint\n",
            "INFO:absl:Loading from checkpoint file completed\n",
            "INFO:absl:Resume training from step 65000\n",
            "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "current step =  65000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d1fd34db0f4914aef3037ddce204de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=100000, style=ProgressStyle(description_width"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Saved checkpoint for step 70000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-14\n",
            "INFO:absl:Saved checkpoint for step 75000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-15\n",
            "INFO:absl:Saved checkpoint for step 80000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-16\n",
            "INFO:absl:Saved checkpoint for step 85000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-17\n",
            "INFO:absl:Saved checkpoint for step 90000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-18\n",
            "INFO:absl:Saved checkpoint for step 95000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-19\n",
            "INFO:absl:Saved checkpoint for step 100000: gs://lila_data/output_dir/un_mark_pass/tf_ckpts/ckpt-20\n",
            "INFO:absl:Saving model checkpoint to /content/drive/My Drive/checkpoints/un_mark_pass/checkpoint-100000\n",
            "Epoch:   0%|          | 0/1 [6:18:45<?, ?it/s]\n",
            "INFO:absl:  Training took time = 6:19:03.575480\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Saving model to /content/drive/My Drive/checkpoints/un_mark_pass\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}